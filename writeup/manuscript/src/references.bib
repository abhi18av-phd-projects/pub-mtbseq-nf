@misc{andrews2012-fastqc,
  title        = {FastQC},
  author       = {Andrews, Simon and Krueger, Felix and {Segonds-Pichon}, Anne and Biggins, Laura and Krueger, Christel and Wingett, Steven},
  year         = {2012},
  month        = jan,
  address      = {Babraham, UK},
  copyright    = {GPL v3},
  abstract     = {FastQC aims to provide a simple way to do some quality control checks on raw sequence data coming from high throughput sequencing pipelines. It provides a modular set of analyses which you can use to give a quick impression of whether your data has any problems of which you should be aware before doing any further analysis.},
  howpublished = {Babraham Institute}
}

@misc{araxismerge,
  title        = {Seqera Cloud Platform},
  author       = {Araxis Limited team},
  year         = {2025},
  url          = {https://www.araxis.com/merge/index.en}
}

@book{arnold2005-java,
  title        = {The Java programming language},
  author       = {Arnold, Ken and Gosling, James and Holmes, David},
  year         = {2005},
  publisher    = {Addison Wesley Professional}
}

@article{berger2022-navigatingbottlenecks,
  title        = {Navigating bottlenecks and trade-offs in genomic data analysis},
  author       = {Berger, Bonnie and Yu, Yun William},
  year         = {2022},
  journal      = {Nature Reviews Genetics},
  pages        = {1--16},
  doi          = {10.1038/s41576-022-00551-z},
  issn         = {1471-0064},
  url          = {https://www.nature.com/articles/s41576-022-00551-z https://www.nature.com/articles/s41576-022-00551-z.pdf},
  abstract     = {Genome sequencing and analysis allow researchers to decode the functional information hidden in DNA sequences as well as to study cell to cell variation within a cell population. Traditionally, the primary bottleneck in genomic analysis pipelines has been the sequencing itself, which has been much more expensive than the computational analyses that follow. However, an important consequence of the continued drive to expand the throughput of sequencing platforms at lower cost is that often the analytical pipelines are struggling to keep up with the sheer amount of raw data produced. Computational cost and efficiency have thus become of ever increasing importance. Recent methodological advances, such as data sketching, accelerators and domain-specific libraries/languages, promise to address these modern computational challenges. However, despite being more efficient, these innovations come with a new set of trade-offs, both expected, such as accuracy versus memory and expense versus time, and more subtle, including the human expertise needed to use non-standard programming interfaces and set up complex infrastructure. In this Review, we discuss how to navigate these new methodological advances and their trade-offs.},
  keywords     = {Genome informatics Genomics Software},
  type         = {Journal Article}
}

@article{daveiga2017-biocontainers,
  title        = {BioContainers: an open-source and community-driven framework for software standardization},
  author       = {da Veiga Leprevost, F. and Gruning, B. A. and Alves Aflitos, S. and Rost, H. L. and Uszkoreit, J. and Barsnes, H. and Vaudel, M. and Moreno, P. and Gatto, L. and Weber, J. and Bai, M. and Jimenez, R. C. and Sachsenberg, T. and Pfeuffer, J. and Vera Alvarez, R. and Griss, J. and Nesvizhskii, A. I. and Perez-Riverol, Y.},
  year         = {2017},
  journal      = {Bioinformatics},
  volume       = {33},
  number       = {16},
  pages        = {2580--2582},
  doi          = {10.1093/bioinformatics/btx192},
  issn         = {1367-4811 (Electronic) 1367-4803 (Print) 1367-4803 (Linking)},
  url          = {https://www.ncbi.nlm.nih.gov/pubmed/28379341},
  note         = {da Veiga Leprevost, Felipe Gruning, Bjorn A Alves Aflitos, Saulo Rost, Hannes L Uszkoreit, Julian Barsnes, Harald Vaudel, Marc Moreno, Pablo Gatto, Laurent Weber, Jonas Bai, Mingze Jimenez, Rafael C Sachsenberg, Timo Pfeuffer, Julianus Vera Alvarez, Roberto Griss, Johannes Nesvizhskii, Alexey I Perez-Riverol, Yasset eng R01 GM094231/GM/NIGMS NIH HHS/ U24 CA210967/CA/NCI NIH HHS/ England 2017/04/06 Bioinformatics. 2017 Aug 15;33(16):2580-2582. doi: 10.1093/bioinformatics/btx192.},
  abstract     = {MOTIVATION: BioContainers (biocontainers.pro) is an open-source and community-driven framework which provides platform independent executable environments for bioinformatics software. BioContainers allows labs of all sizes to easily install bioinformatics software, maintain multiple versions of the same software and combine tools into powerful analysis pipelines. BioContainers is based on popular open-source projects Docker and rkt frameworks, that allow software to be installed and executed under an isolated and controlled environment. Also, it provides infrastructure and basic guidelines to create, manage and distribute bioinformatics containers with a special focus on omics technologies. These containers can be integrated into more comprehensive bioinformatics pipelines and different architectures (local desktop, cloud environments or HPC clusters). AVAILABILITY AND IMPLEMENTATION: The software is freely available at github.com/BioContainers/. CONTACT: yperez@ebi.ac.uk.},
  keywords     = {Computational Biology/*methods Genomics/methods Metabolomics/methods Proteomics/methods *Software},
  type         = {Journal Article}
}

@article{ewels2016-multiqc,
  title        = {MultiQC: summarize analysis results for multiple tools and samples in a single report},
  author       = {Ewels, P. and Magnusson, M. and Lundin, S. and Käller, M.},
  year         = {2016},
  journal      = {Bioinformatics},
  volume       = {32},
  number       = {19},
  pages        = {3047--3048},
  doi          = {10.1093/bioinformatics/btw354},
  issn         = {1367-4803},
  url          = {<Go to ISI>://WOS:000386020100028},
  note         = {Dz7bx Times Cited:3897 Cited References Count:6},
  abstract     = {Motivation: Fast and accurate quality control is essential for studies involving next-generation sequencing data. Whilst numerous tools exist to quantify QC metrics, there is no common approach to flexibly integrate these across tools and large sample sets. Assessing analysis results across an entire project can be time consuming and error prone; batch effects and outlier samples can easily be missed in the early stages of analysis. Results: We present MultiQC, a tool to create a single report visualising output from multiple tools across many samples, enabling global trends and biases to be quickly identified. MultiQC can plot data from many common bioinformatics tools and is built to allow easy extension and customization.},
  type         = {Journal Article}
}

@article{ewels2020-nfcore,
  title        = {The nf-core framework for community-curated bioinformatics pipelines},
  author       = {Ewels, Philip A. and Peltzer, Alexander and Fillinger, Sven and Patel, Harshil and Alneberg, Johannes and Wilm, Andreas and Garcia, Maxime Ulysse and Di Tommaso, Paolo and Nahnsen, Sven},
  year         = {2020},
  journal      = {Nature Biotechnology},
  volume       = {38},
  number       = {3},
  pages        = {276--278},
  doi          = {10.1038/s41587-020-0439-x},
  issn         = {1087-0156, 1546-1696},
  url          = {https://www.nature.com/articles/s41587-020-0439-x},
  type         = {Journal Article}
}

@article{grealey2022-bioinfocarbon,
  title        = {The Carbon Footprint of Bioinformatics},
  author       = {Grealey, J. and Lannelongue, L. and Saw, W. Y. and Marten, J. and Meric, G. and Ruiz-Carmona, S. and Inouye, M.},
  year         = {2022},
  journal      = {Mol Biol Evol},
  volume       = {39},
  number       = {3},
  doi          = {10.1093/molbev/msac034},
  issn         = {1537-1719 (Electronic) 0737-4038 (Print) 0737-4038 (Linking)},
  url          = {https://www.ncbi.nlm.nih.gov/pubmed/35143670},
  note         = {Grealey, Jason Lannelongue, Loic Saw, Woei-Yuh Marten, Jonathan Meric, Guillaume Ruiz-Carmona, Sergio Inouye, Michael eng MR/S502443/1/MRC_/Medical Research Council/United Kingdom BRC-1215-20014/DH_/Department of Health/United Kingdom MR/L003120/1/MRC_/Medical Research Council/United Kingdom RG/18/13/33946/BHF_/British Heart Foundation/United Kingdom WT_/Wellcome Trust/United Kingdom CSO_/Chief Scientist Office/United Kingdom RG/13/13/30194/BHF_/British Heart Foundation/United Kingdom Research Support, Non-U.S. Gov't 2022/02/11 Mol Biol Evol. 2022 Mar 2;39(3):msac034. doi: 10.1093/molbev/msac034.},
  abstract     = {Bioinformatic research relies on large-scale computational infrastructures which have a nonzero carbon footprint but so far, no study has quantified the environmental costs of bioinformatic tools and commonly run analyses. In this work, we estimate the carbon footprint of bioinformatics (in kilograms of CO2 equivalent units, kgCO2e) using the freely available Green Algorithms calculator (www.green-algorithms.org, last accessed 2022). We assessed 1) bioinformatic approaches in genome-wide association studies (GWAS), RNA sequencing, genome assembly, metagenomics, phylogenetics, and molecular simulations, as well as 2) computation strategies, such as parallelization, CPU (central processing unit) versus GPU (graphics processing unit), cloud versus local computing infrastructure, and geography. In particular, we found that biobank-scale GWAS emitted substantial kgCO2e and simple software upgrades could make it greener, for example, upgrading from BOLT-LMM v1 to v2.3 reduced carbon footprint by 73%. Moreover, switching from the average data center to a more efficient one can reduce carbon footprint by approximately 34%. Memory over-allocation can also be a substantial contributor to an algorithm's greenhouse gas emissions. The use of faster processors or greater parallelization reduces running time but can lead to greater carbon footprint. Finally, we provide guidance on how researchers can reduce power consumption and minimize kgCO2e. Overall, this work elucidates the carbon footprint of common analyses in bioinformatics and provides solutions which empower a move toward greener research.},
  keywords     = {Algorithms *Carbon Footprint *Computational Biology Genome-Wide Association Study Software bioinformatics carbon footprint genomics green algorithms},
  type         = {Journal Article}
}

@article{gruning2018-bioconda,
  title        = {Bioconda: sustainable and comprehensive software distribution for the life sciences},
  author       = {Gruning, B. and Dale, R. and Sjodin, A. and Chapman, B. A. and Rowe, J. and Tomkins-Tinch, C. H. and Valieris, R. and Koster, J. and Bioconda, Team},
  year         = {2018},
  journal      = {Nat Methods},
  volume       = {15},
  number       = {7},
  pages        = {475--476},
  doi          = {10.1038/s41592-018-0046-7},
  issn         = {1548-7105 (Electronic) 1548-7091 (Print) 1548-7091 (Linking)},
  url          = {https://www.ncbi.nlm.nih.gov/pubmed/29967506 https://pmc.ncbi.nlm.nih.gov/articles/PMC11070151/pdf/nihms-1593812.pdf},
  note         = {Gruning, Bjorn Dale, Ryan Sjodin, Andreas Chapman, Brad A Rowe, Jillian Tomkins-Tinch, Christopher H Valieris, Renan Koster, Johannes eng MC_PC_15065/MRC_/Medical Research Council/United Kingdom ZIC HD008986/ImNIH/Intramural NIH HHS/ Letter Research Support, N.I.H., Extramural Research Support, Non-U.S. Gov't 2018/07/04 Nat Methods. 2018 Jul;15(7):475-476. doi: 10.1038/s41592-018-0046-7.},
  keywords     = {Computational Biology *Software User-Computer Interface},
  type         = {Journal Article}
}

@article{jana2016-iqtree,
  title        = {W-IQ-TREE: a fast online phylogenetic tool for maximum likelihood analysis},
  author       = {Trifinopoulos, Jana and Nguyen, Lam-Tung and von Haeseler, Arndt and Minh, Bui Quang},
  year         = {2016},
  month        = {04},
  journal      = {Nucleic Acids Research},
  volume       = {44},
  number       = {W1},
  pages        = {W232-W235},
  doi          = {10.1093/nar/gkw256},
  issn         = {0305-1048},
  url          = {https://doi.org/10.1093/nar/gkw256},
  abstract     = {This article presents W-IQ-TREE, an intuitive and user-friendly web interface and server for IQ-TREE, an efficient phylogenetic software for maximum likelihood analysis. W-IQ-TREE supports multiple sequence types (DNA, protein, codon, binary and morphology) in common alignment formats and a wide range of evolutionary models including mixture and partition models. W-IQ-TREE performs fast model selection, partition scheme finding, efficient tree reconstruction, ultrafast bootstrapping, branch tests, and tree topology tests. All computations are conducted on a dedicated computer cluster and the users receive the results via URL or email. W-IQ-TREE is available at http://iqtree.cibiv.univie.ac.at. It is free and open to all users and there is no login requirement.},
  eprint       = {https://academic.oup.com/nar/article-pdf/44/W1/W232/7631557/gkw256.pdf}
}

@article{kadri2022-containers,
  title        = {Containers in Bioinformatics , ,},
  author       = {Kadri, S. and Sboner, A. and Sigaras, A. and Roy, S.},
  year         = {2022},
  journal      = {Journal of Molecular Diagnostics},
  volume       = {24},
  number       = {5},
  pages        = {442--454},
  doi          = {10.1016/j.jmoldx.2022.01.006},
  issn         = {1525-1578},
  url          = {<Go to ISI>://WOS:000806495700004},
  note         = {1w0ua Times Cited:10 Cited References Count:25},
  abstract     = {Systematic implementation of bioinformatics resources for next generation sequencing (NGS)-based clinical testing is an arduous undertaking. One of the key challenges involves developing an ecosystem of information technology infrastructure for enabling scalable and reproducible bioinformatics services that is resilient and secure for handling genetic and protected health information, often embedded in an existing non-bioinformatics-oriented infrastructure. Container technology provides an ideal and infrastructure-agnostic solution for molecular laboratories developing and using bioinformatics pipelines, whether on-premise or using the cloud. A container is a technology that provides a consistent computational environment and enables reproducibility, scalability, and security when developing NGS bioinformatics analysis pipelines. Containers can increase the bioinformatics team's productivity by automating and simplifying the maintenance of complex bioinformatics resources, as well as facilitate validation, version control, and documentation necessary for clinical laboratory regulatory compliance. Although there is increasing popularity in adopting containers for developing NGS bioinformatics pipelines, there is wide variability and inconsistency in the usage of containers that may result in suboptimal performance and potentially compromise the security and privacy of protected health information. In this article, the authors highlight the current state and provide best or recommended practices for building, using containers in NGS bioinformatics solutions in a clinical setting with focus on scalability, optimization, maintainability, and data security.},
  type         = {Journal Article}
}

@article{kohl2018-mtbseq,
  title        = {MTBseq: a comprehensive pipeline for whole genome sequence analysis of Mycobacterium tuberculosis complex isolates},
  author       = {Kohl, T. A. and Utpatel, C. and Schleusener, V. and De Filippo, M. R. and Beckert, P. and Cirillo, D. M. and Niemann, S.},
  year         = {2018},
  journal      = {PeerJ},
  volume       = {6},
  pages        = {e5895},
  doi          = {10.7717/peerj.5895},
  issn         = {2167-8359 (Print) 2167-8359 (Electronic) 2167-8359 (Linking)},
  url          = {https://www.ncbi.nlm.nih.gov/pubmed/30479891},
  note         = {Kohl, Thomas Andreas Utpatel, Christian Schleusener, Viola De Filippo, Maria Rosaria Beckert, Patrick Cirillo, Daniela Maria Niemann, Stefan eng 2018/11/28 PeerJ. 2018 Nov 13;6:e5895. doi: 10.7717/peerj.5895. eCollection 2018.},
  abstract     = {Analyzing whole-genome sequencing data of Mycobacterium tuberculosis complex (MTBC) isolates in a standardized workflow enables both comprehensive antibiotic resistance profiling and outbreak surveillance with highest resolution up to the identification of recent transmission chains. Here, we present MTBseq, a bioinformatics pipeline for next-generation genome sequence data analysis of MTBC isolates. Employing a reference mapping based workflow, MTBseq reports detected variant positions annotated with known association to antibiotic resistance and performs a lineage classification based on phylogenetic single nucleotide polymorphisms (SNPs). When comparing multiple datasets, MTBseq provides a joint list of variants and a FASTA alignment of SNP positions for use in phylogenomic analysis, and identifies groups of related isolates. The pipeline is customizable, expandable and can be used on a desktop computer or laptop without any internet connection, ensuring mobile usage and data security. MTBseq and accompanying documentation is available from https://github.com/ngs-fzb/MTBseq_source.},
  keywords     = {Antibiotic resistance profiling Automated analysis pipeline Bacterial epidemiology Bacterial genome analysis Mycobacterium tuberculosis complex Next-generation sequencing Phylogeny Whole-genome sequencing},
  type         = {Journal Article}
}

@article{kurtzer2017-singularity,
  title        = {Singularity: Scientific containers for mobility of compute},
  author       = {Kurtzer, G. M. and Sochat, V. and Bauer, M. W.},
  year         = {2017},
  journal      = {Plos One},
  volume       = {12},
  number       = {5},
  doi          = {ARTN e0177459 10.1371/journal.pone.0177459},
  issn         = {1932-6203},
  url          = {<Go to ISI>://WOS:000401314300116},
  note         = {Eu8up Times Cited:792 Cited References Count:29},
  abstract     = {Here we present Singularity, software developed to bring containers and reproducibility to scientific computing. Using Singularity containers, developers can work in reproducible environments of their choosing and design, and these complete environments can easily be copied and executed on other platforms. Singularity is an open source initiative that harnesses the expertise of system and software engineers and researchers alike, and integrates seam-lessly into common workflows for both of these groups. As its primary use case, Singularity brings mobility of computing to both users and HPC centers, providing a secure means to capture and distribute software and compute environments. This ability to create and deploy reproducible environments across these centers, a previously unmet need, makes Singularity a game changing development for computational science.},
  type         = {Journal Article}
}


@article{langer2025,
   author = {Langer, Björn E. and Amaral, Andreia and Baudement, Marie-Odile and Bonath, Franziska and Charles, Mathieu and Chitneedi, Praveen Krishna and Clark, Emily L. and Di Tommaso, Paolo and Djebali, Sarah and Ewels, Philip A. and Eynard, Sonia and Fellows Yates, James A. and Fischer, Daniel and Floden, Evan W. and Foissac, Sylvain and Gabernet, Gisela and Garcia, Maxime U. and Gillard, Gareth and Gundappa, Manu Kumar and Guyomar, Cervin and Hakkaart, Christopher and Hanssen, Friederike and Harrison, Peter W. and Hörtenhuber, Matthias and Kurylo, Cyril and Kühn, Christa and Lagarrigue, Sandrine and Lallias, Delphine and Macqueen, Daniel J. and Miller, Edmund and Mir-Pedrol, Júlia and Moreira, Gabriel Costa Monteiro and Nahnsen, Sven and Patel, Harshil and Peltzer, Alexander and Pitel, Frederique and Ramayo-Caldas, Yuliaxis and Ribeiro-Dantas, Marcel da Câmara and Rocha, Dominique and Salavati, Mazdak and Sokolov, Alexey and Espinosa-Carrasco, Jose and Notredame, Cedric and community, the nf-core},
   title = {Empowering bioinformatics communities with Nextflow and nf-core},
   journal = {Genome Biology},
   volume = {26},
   number = {1},
   pages = {228},
   abstract = {Standardized analysis pipelines contribute to making data bioinformatics research compliant with the paradigm of Findability, Accessibility, Interoperability, and Reusability (FAIR), and facilitate collaboration. Nextflow and Snakemake, two popular command-line solutions, are increasingly adopted by users, complementing GUI-based platforms such as Galaxy. We report recent developments of the nf-core framework with the new Nextflow Domain-Specific Language (DSL2). An extensive library of modules and subworkflows enables research communities to adopt common standards progressively, as resources and needs allow. We present an overview of some of the research communities built around nf-core and showcase its adoption by six EuroFAANG farmed animal research consortia.},
   ISSN = {1474-760X},
   DOI = {10.1186/s13059-025-03673-9},
   url = {https://doi.org/10.1186/s13059-025-03673-9
https://genomebiology.biomedcentral.com/counter/pdf/10.1186/s13059-025-03673-9.pdf},
   year = {2025},
   type = {Journal Article}
}




@article{li2009-bwa,
  title        = {Fast and accurate short read alignment with Burrows-Wheeler transform},
  author       = {Li, H. and Durbin, R.},
  year         = {2009},
  journal      = {Bioinformatics},
  volume       = {25},
  number       = {14},
  pages        = {1754--1760},
  doi          = {10.1093/bioinformatics/btp324},
  issn         = {1367-4803},
  url          = {<Go to ISI>://WOS:000267665900006},
  note         = {466mi Times Cited:32862 Cited References Count:17},
  abstract     = {Motivation: The enormous amount of short reads generated by the new DNA sequencing technologies call for the development of fast and accurate read alignment programs. A first generation of hash table-based methods has been developed, including MAQ, which is accurate, feature rich and fast enough to align short reads from a single individual. However, MAQ does not support gapped alignment for single-end reads, which makes it unsuitable for alignment of longer reads where indels may occur frequently. The speed of MAQ is also a concern when the alignment is scaled up to the resequencing of hundreds of individuals. Results: We implemented Burrows-Wheeler Alignment tool (BWA), a new read alignment package that is based on backward search with Burrows-Wheeler Transform (BWT), to efficiently align short sequencing reads against a large reference sequence such as the human genome, allowing mismatches and gaps. BWA supports both base space reads, e. g. from Illumina sequencing machines, and color space reads from AB SOLiD machines. Evaluations on both simulated and real data suggest that BWA is similar to 10-20 x faster than MAQ, while achieving similar accuracy. In addition, BWA outputs alignment in the new standard SAM (Sequence Alignment/Map) format. Variant calling and other downstream analyses after the alignment can be achieved with the open source SAMtools software package.},
  keywords     = {genome oligonucleotides sequences program space DNA},
  type         = {Journal Article}
}

@article{li2009-samtools,
  title        = {The Sequence Alignment/Map format and SAMtools},
  author       = {Li, H. and Handsaker, B. and Wysoker, A. and Fennell, T. and Ruan, J. and Homer, N. and Marth, G. and Abecasis, G. and Durbin, R. and Proc, 1000 Genome Project Data},
  year         = {2009},
  journal      = {Bioinformatics},
  volume       = {25},
  number       = {16},
  pages        = {2078--2079},
  doi          = {10.1093/bioinformatics/btp352},
  issn         = {1367-4803},
  url          = {<Go to ISI>://WOS:000268808600014},
  note         = {481kj Times Cited:16525 Cited References Count:4},
  abstract     = {The Sequence Alignment/Map (SAM) format is a generic alignment format for storing read alignments against reference sequences, supporting short and long reads (up to 128 Mbp) produced by different sequencing platforms. It is flexible in style, compact in size, efficient in random access and is the format in which alignments from the 1000 Genomes Project are released. SAMtools implements various utilities for post-processing alignments in the SAM format, such as indexing, variant caller and alignment viewer, and thus provides universal tools for processing read alignments.},
  keywords     = {human genome},
  type         = {Journal Article}
}

@article{loic2024-greener,
  title        = {GREENER principles for environmentally sustainable computational science},
  author       = {Lannelongue, L. and Aronson, H. G. and Bateman, A. and Birney, E. and Caplan, T. and Juckes, M. and McEntyre, J. and Morris, A. D. and Reilly, G. and Inouye, M.},
  year         = {2023},
  journal      = {Nat Comput Sci},
  volume       = {3},
  number       = {6},
  pages        = {514--521},
  doi          = {10.1038/s43588-023-00461-y},
  issn         = {2662-8457 (Electronic) 2662-8457 (Linking)},
  url          = {https://www.ncbi.nlm.nih.gov/pubmed/38177425},
  note         = {Lannelongue, Loic Aronson, Hans-Erik G Bateman, Alex Birney, Ewan Caplan, Talia Juckes, Martin McEntyre, Johanna Morris, Andrew D Reilly, Gerry Inouye, Michael eng MR/S502443/1/RCUK | Medical Research Council (MRC)/ RG/18/13/33946/British Heart Foundation (BHF)/ RG/13/13/30194/British Heart Foundation (BHF)/ Review 2024/01/05 Nat Comput Sci. 2023 Jun;3(6):514-521. doi: 10.1038/s43588-023-00461-y. Epub 2023 Jun 26.},
  abstract     = {The carbon footprint of scientific computing is substantial, but environmentally sustainable computational science (ESCS) is a nascent field with many opportunities to thrive. To realize the immense green opportunities and continued, yet sustainable, growth of computer science, we must take a coordinated approach to our current challenges, including greater awareness and transparency, improved estimation and wider reporting of environmental impacts. Here, we present a snapshot of where ESCS stands today and introduce the GREENER set of principles, as well as guidance for best practices moving forward.},
  type         = {Journal Article}
}

@article{mckenna2010-gatk,
  title        = {The Genome Analysis Toolkit: A MapReduce framework for analyzing next-generation DNA sequencing data},
  author       = {McKenna, A. and Hanna, M. and Banks, E. and Sivachenko, A. and Cibulskis, K. and Kernytsky, A. and Garimella, K. and Altshuler, D. and Gabriel, S. and Daly, M. and DePristo, M. A.},
  year         = {2010},
  journal      = {Genome Research},
  volume       = {20},
  number       = {9},
  pages        = {1297--1303},
  doi          = {10.1101/gr.107524.110},
  issn         = {1088-9051},
  url          = {<Go to ISI>://WOS:000281520400015},
  note         = {646eq Times Cited:18402 Cited References Count:27},
  abstract     = {Next-generation DNA sequencing (NGS) projects, such as the 1000 Genomes Project, are already revolutionizing our understanding of genetic variation among individuals. However, the massive data sets generated by NGS the 1000 Genome pilot alone includes nearly five terabases-make writing feature-rich, efficient, and robust analysis tools difficult for even computationally sophisticated individuals. Indeed, many professionals are limited in the scope and the ease with which they can answer scientific questions by the complexity of accessing and manipulating the data produced by these machines. Here, we discuss our Genome Analysis Toolkit (GATK), a structured programming framework designed to ease the development of efficient and robust analysis tools for next-generation DNA sequencers using the functional programming philosophy of MapReduce. The GATK provides a small but rich set of data access patterns that encompass the majority of analysis tool needs. Separating specific analysis calculations from common data management infrastructure enables us to optimize the GATK framework for correctness, stability, and CPU and memory efficiency and to enable distributed and shared memory parallelization. We highlight the capabilities of the GATK by describing the implementation and application of robust, scale-tolerant tools like coverage calculators and single nucleotide polymorphism (SNP) calling. We conclude that the GATK programming framework enables developers and analysts to quickly and easily write efficient and robust NGS tools, many of which have already been incorporated into large-scale sequencing projects like the 1000 Genomes Project and The Cancer Genome Atlas.},
  keywords     = {structural variation quality assessment short-read alignment mhc},
  type         = {Journal Article}
}

@article{merkel2014-docker,
  title        = {Docker: lightweight linux containers for consistent development and deployment},
  author       = {Merkel, Dirk},
  year         = {2014},
  journal      = {Linux journal},
  volume       = {2014},
  number       = {239},
  pages        = {2}
}

@inproceedings{patricia2023-aerial,
  title        = {Nasal and Amnion Methylomes: Biomarkers for Smoke Exposure and Maternal Asthma},
  author       = {Agudelo-Romero, Patricia and Iosifidis, Thomas and Kicic-Starcevich, Elizabeth and Hancock, David and Caparros-Martin, Jose and Martino, David and Stick, Stephen},
  booktitle    = {Journal of Allergy and Clinical Immunology},
  publisher    = {Elsevier},
  volume       = {153},
  pages        = {AB243},
  doi          = {10.1016/j.jaci.2023.11.779},
  isbn         = {0091-6749},
  url          = {https://doi.org/10.1016/j.jaci.2023.11.779},
  note         = {doi: 10.1016/j.jaci.2023.11.779},
  type         = {Conference Proceedings}
}

@online{picard2019,
  title        = {Picard toolkit},
  year         = {2019},
  url          = {https://broadinstitute.github.io/picard/}
}

@misc{r-lang,
  title        = {R: A Language and Environment for Statistical Computing},
  author       = {R Core Team},
  year         = {2023},
  address      = {Vienna, Austria},
  url          = {https://www.R-project.org/},
  organization = {R Foundation for Statistical Computing}
}

@article{schleusener2017-tbresistancepred,
  title        = {Mycobacterium tuberculosis resistance prediction and lineage classification from genome sequencing: comparison of automated analysis tools},
  author       = {Schleusener, V. and Koser, C. U. and Beckert, P. and Niemann, S. and Feuerriegel, S.},
  year         = {2017},
  journal      = {Sci Rep},
  volume       = {7},
  pages        = {46327},
  doi          = {10.1038/srep46327},
  issn         = {2045-2322 (Electronic) 2045-2322 (Linking)},
  url          = {https://www.ncbi.nlm.nih.gov/pubmed/28425484},
  note         = {Schleusener, Viola Koser, Claudio U Beckert, Patrick Niemann, Stefan Feuerriegel, Silke eng England 2017/04/21 Sci Rep. 2017 Apr 20;7:46327. doi: 10.1038/srep46327.},
  abstract     = {Whole-genome sequencing (WGS) has the potential to accelerate drug-susceptibility testing (DST) to design appropriate regimens for drug-resistant tuberculosis (TB). Several recently developed automated software tools promise to standardize the analysis and interpretation of WGS data. We assessed five tools (CASTB, KvarQ, Mykrobe Predictor TB, PhyResSE, and TBProfiler) with regards to DST and phylogenetic lineage classification, which we compared with phenotypic DST, Sanger sequencing, and traditional typing results for a collection of 91 strains. The lineage classifications by the tools generally only differed in the resolution of the results. However, some strains could not be classified at all and one strain was misclassified. The sensitivities and specificities for isoniazid and rifampicin resistance of the tools were high, whereas the results for ethambutol, pyrazinamide, and streptomycin resistance were more variable. False-susceptible DST results were mainly due to missing mutations in the resistance catalogues that the respective tools employed for data interpretation. Notably, we also found cases of false-resistance because of the misclassification of polymorphisms as resistance mutations. In conclusion, the performance of current WGS analysis tools for DST is highly variable. Sustainable business models and a shared, high-quality catalogue of resistance mutations are needed to ensure the clinical utility of these tools.},
  keywords     = {Antitubercular Agents/*pharmacology Computational Biology/methods *Drug Resistance, Multiple, Bacterial *Genome, Bacterial Genomics/methods Humans Microbial Sensitivity Tests Mycobacterium tuberculosis/classification/*drug effects/*genetics Phylogeny Software Tuberculosis/*microbiology Whole Genome Sequencing},
  type         = {Journal Article}
}

@misc{seqeracloud,
  title        = {Seqera Cloud Platform},
  author       = {Di Tommaso, Paolo and Floden, Evan W. and Seqera Labs team},
  year         = {2025},
  url          = {https://seqera.io/}
}

@article{stephens2015-genomicaldata,
  title        = {Big Data: Astronomical or Genomical?},
  author       = {Stephens, Zachary D. AND Lee, Skylar Y. AND Faghri, Faraz AND Campbell, Roy H. AND Zhai, Chengxiang AND Efron, Miles J. AND Iyer, Ravishankar AND Schatz, Michael C. AND Sinha, Saurabh AND Robinson, Gene E.},
  year         = {2015},
  month        = {07},
  journal      = {PLOS Biology},
  publisher    = {Public Library of Science},
  volume       = {13},
  number       = {7},
  pages        = {1--11},
  doi          = {10.1371/journal.pbio.1002195},
  url          = {https://doi.org/10.1371/journal.pbio.1002195},
  abstract     = {Genomics is a Big Data science and is going to get much bigger, very soon, but it is not known whether the needs of genomics will exceed other Big Data domains. Projecting to the year 2025, we compared genomics with three other major generators of Big Data: astronomy, YouTube, and Twitter. Our estimates show that genomics is a “four-headed beast”—it is either on par with or the most demanding of the domains analyzed here in terms of data acquisition, storage, distribution, and analysis. We discuss aspects of new technologies that will need to be developed to rise up and meet the computational challenges that genomics poses for the near future. Now is the time for concerted, community-wide planning for the “genomical” challenges of the next decade.}
}

@article{sztuka2024-nextflowvsbash,
  title        = {Nextflow vs. plain bash: different approaches to the parallelization of SNP calling from the whole genome sequence data},
  author       = {Sztuka, M. and Kotlarz, K. and Mielczarek, M. and Hajduk, P. and Liu, J. and Szyda, J.},
  year         = {2024},
  journal      = {NAR Genom Bioinform},
  volume       = {6},
  number       = {2},
  pages        = {lqae040},
  doi          = {10.1093/nargab/lqae040},
  issn         = {2631-9268 (Electronic) 2631-9268 (Linking)},
  url          = {https://www.ncbi.nlm.nih.gov/pubmed/38686136},
  note         = {Sztuka, Marek Kotlarz, Krzysztof Mielczarek, Magda Hajduk, Piotr Liu, Jakub Szyda, Joanna eng England 2024/04/30 NAR Genom Bioinform. 2024 Apr 29;6(2):lqae040. doi: 10.1093/nargab/lqae040. eCollection 2024 Jun.},
  abstract     = {This study compared computational approaches to parallelization of an SNP calling workflow. The data comprised DNA from five Holstein-Friesian cows sequenced with the Illumina platform. The pipeline consisted of quality control, alignment to the reference genome, post-alignment, and SNP calling. Three approaches to parallelization were compared: (i) a plain Bash script in which a pipeline for each cow was executed as separate processes invoked at the same time, (ii) a Bash script wrapped in a single Nextflow process and (iii) a Nextflow script with each component of the pipeline defined as a separate process. The results demonstrated that on average, the multi-process Nextflow script performed 15-27% faster depending on the number of assigned threads, with the biggest execution time advantage over the plain Bash approach observed with 10 threads. In terms of RAM usage, the most substantial variation was observed for the multi-process Nextflow, for which it increased with the number of assigned threads, while RAM consumption of the other setups did not depend much on the number of threads assigned for computations. Due to intermediate and log files generated, disk usage was markedly higher for the multi-process Nextflow than for the plain Bash and for the single-process Nextflow.},
  type         = {Journal Article}
}

@article{tommaso2015-docker,
  title        = {The impact of Docker containers on the performance of genomic pipelines},
  author       = {Di Tommaso, P. and Palumbo, E. and Chatzou, M. and Prieto, P. and Heuer, M. L. and Notredame, C.},
  year         = {2015},
  journal      = {Peerj},
  volume       = {3},
  doi          = {ARTN e1273 10.7717/peerj.1273},
  issn         = {2167-8359},
  url          = {<Go to ISI>://WOS:000364327000005},
  note         = {Cv5qv Times Cited:68 Cited References Count:18},
  abstract     = {Genomic pipelines consist of several pieces of third party software and, because of their experimental nature, frequent changes and updates are commonly necessary thus raising serious deployment and reproducibility issues. Docker containers are emerging as a possible solution for many of these problems, as they allow the packaging of pipelines in an isolated and self-contained manner. This makes it easy to distribute and execute pipelines in a portable manner across a wide range of computing platforms. Thus, the question that arises is to what extent the use of Docker containers might affect the performance of these pipelines. Here we address this question and conclude that Docker containers have only a minor impact on the performance of common genomic pipelines, which is negligible when the executed jobs are long in terms of computational time.},
  keywords     = {workflow pipelines docker virtualisation bioinformatics read alignment},
  type         = {Journal Article}
}

@article{tommaso2017-nextflow,
  title        = {Nextflow enables reproducible computational workflows},
  author       = {Di Tommaso, Paolo and Chatzou, Maria and Floden, Evan W. and Barja, Pablo Prieto and Palumbo, Emilio and Notredame, Cedric},
  year         = {2017},
  journal      = {Nature Biotechnology},
  volume       = {35},
  number       = {4},
  pages        = {316--319},
  doi          = {10.1038/nbt.3820},
  issn         = {1087-0156, 1546-1696},
  url          = {https://www.nature.com/articles/nbt.3820.pdf},
  type         = {Journal Article}
}

@misc{wall1994-perl,
  title        = {The Perl programming language},
  author       = {Wall, Larry and others},
  year         = {1994},
  publisher    = {Prentice Hall Software Series}
}
